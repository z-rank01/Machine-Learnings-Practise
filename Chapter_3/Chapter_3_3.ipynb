{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] \n",
      "\n",
      "   label  alcohol  malic acid   ash  alcalinity of ash  magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   total phenols  flavanoids  nonflavanoid phenols  proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   color intensity   hue  OD280/OD315 of diluted wines  proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# scale datasets uniformly\n",
    "\n",
    "# load up new datasets - wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['label', 'alcohol', 'malic acid', 'ash', 'alcalinity of ash', \n",
    "                   'magnesium', 'total phenols', 'flavanoids', 'nonflavanoid phenols', \n",
    "                   'proanthocyanins', 'color intensity', 'hue', \n",
    "                   'OD280/OD315 of diluted wines', 'proline']\n",
    "print(np.unique(df_wine['label']), '\\n')\n",
    "print(df_wine.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3      4     5     6     7     8    9     10    11  \\\n",
      "0  13.62  4.95  2.35  20.0   92.0  2.00  0.80  0.47  1.02  4.4  0.91  2.05   \n",
      "1  13.76  1.53  2.70  19.5  132.0  2.95  2.74  0.50  1.35  5.4  1.25  3.00   \n",
      "2  13.73  1.50  2.70  22.5  101.0  3.00  3.25  0.29  2.38  5.7  1.19  2.71   \n",
      "3  13.51  1.80  2.65  19.0  110.0  2.35  2.53  0.29  1.54  4.2  1.10  2.87   \n",
      "4  12.60  2.46  2.20  18.5   94.0  1.62  0.66  0.63  0.94  7.1  0.73  1.58   \n",
      "\n",
      "       12  \n",
      "0   550.0  \n",
      "1  1235.0  \n",
      "2  1285.0  \n",
      "3  1095.0  \n",
      "4   695.0  \n",
      "   0\n",
      "0  3\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  3\n"
     ]
    }
   ],
   "source": [
    "# split datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "print(pd.DataFrame(X_train).head())\n",
    "print(pd.DataFrame(y_train).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6     7   \\\n",
      "0  0.646199  0.832016  0.424837  0.462366  0.271605  0.351724  0.097046  0.68   \n",
      "1  0.687135  0.156126  0.653595  0.435484  0.765432  0.679310  0.506329  0.74   \n",
      "2  0.678363  0.150198  0.653595  0.596774  0.382716  0.696552  0.613924  0.32   \n",
      "3  0.614035  0.209486  0.620915  0.408602  0.493827  0.472414  0.462025  0.32   \n",
      "4  0.347953  0.339921  0.326797  0.381720  0.296296  0.220690  0.067511  1.00   \n",
      "\n",
      "         8         9         10        11        12  \n",
      "0  0.189873  0.236234  0.457447  0.285714  0.194009  \n",
      "1  0.294304  0.325044  0.819149  0.633700  0.682596  \n",
      "2  0.620253  0.351687  0.755319  0.527473  0.718260  \n",
      "3  0.354430  0.218472  0.659574  0.586081  0.582739  \n",
      "4  0.164557  0.476021  0.265957  0.113553  0.297432  \n"
     ]
    }
   ],
   "source": [
    "# scale training datasets and apply the \n",
    "# fitted scalar to test and other datasets\n",
    "\n",
    "# min-max scalar (normalize)\n",
    "# -----------------\n",
    "# min-max scalar scale the datasets into range of 0.0 and 1.0 \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)\n",
    "print(pd.DataFrame(X_train_norm).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.712259  2.220487 -0.130259  0.059629 -0.504327 -0.528316 -1.240000   \n",
      "1  0.882292 -0.704572  1.175336 -0.090655  2.341479  1.016759  0.662995   \n",
      "2  0.845856 -0.730230  1.175336  0.811048  0.135979  1.098079  1.163267   \n",
      "3  0.578661 -0.473646  0.988823 -0.240939  0.776285  0.040922  0.457000   \n",
      "4 -0.526554  0.090839 -0.689799 -0.391223 -0.362037 -1.146346 -1.377330   \n",
      "\n",
      "         7         8         9         10        11        12  \n",
      "0  0.841180 -1.052151 -0.292189 -0.200170 -0.821641 -0.629464  \n",
      "1  1.088743 -0.492935  0.131521  1.339826  0.549313  1.475688  \n",
      "2 -0.644195  1.252496  0.258634  1.068062  0.130811  1.629349  \n",
      "3 -0.644195 -0.170963 -0.376931  0.660416  0.361708  1.045438  \n",
      "4  2.161513 -1.187719  0.851827 -1.015462 -1.499903 -0.183848  \n"
     ]
    }
   ],
   "source": [
    "# standard scalar (standardize)\n",
    "# -----------------------------\n",
    "# standard scalar scale datasets into range of -1.0 and 1.0\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_std = ss.fit_transform(X_train)\n",
    "X_test_std = ss.transform(X_test)\n",
    "print(pd.DataFrame(X_train_std).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized: \n",
      "          0\n",
      "0 -1.46385\n",
      "1 -0.87831\n",
      "2 -0.29277\n",
      "3  0.29277\n",
      "4  0.87831\n",
      "5  1.46385\n",
      "normalize: \n",
      "      0\n",
      "0  0.0\n",
      "1  0.2\n",
      "2  0.4\n",
      "3  0.6\n",
      "4  0.8\n",
      "5  1.0\n"
     ]
    }
   ],
   "source": [
    "# manully normalize and standardize\n",
    "# ---------------------------------\n",
    "ex = np.array([0, 1, 2, 3, 4, 5])\n",
    "print('standardized: \\n', pd.DataFrame((ex - np.mean(ex)) / np.std(ex)))\n",
    "print('normalize: \\n', pd.DataFrame((ex - ex.min()) / (ex.max() - ex.min())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.416510  2.003226 -0.057971  0.119048 -0.301370 -0.396135 -0.821053   \n",
      "1  0.521576 -0.203226  0.956522  0.000000  1.890411  0.521739  0.345865   \n",
      "2  0.499062 -0.222581  0.956522  0.714286  0.191781  0.570048  0.652632   \n",
      "3  0.333959 -0.029032  0.811594 -0.119048  0.684932 -0.057971  0.219549   \n",
      "4 -0.348968  0.396774 -0.492754 -0.238095 -0.191781 -0.763285 -0.905263   \n",
      "\n",
      "         7         8         9         10        11        12  \n",
      "0  0.753623 -0.804196 -0.116667 -0.166667 -0.652452 -0.230949  \n",
      "1  0.927536 -0.342657  0.216667  0.863636  0.157783  1.050023  \n",
      "2 -0.289855  1.097902  0.316667  0.681818 -0.089552  1.143525  \n",
      "3 -0.289855 -0.076923 -0.183333  0.409091  0.046908  0.788219  \n",
      "4  1.681159 -0.916084  0.783333 -0.712121 -1.053305  0.040206  \n"
     ]
    }
   ],
   "source": [
    "# Robust Scalar\n",
    "# -------------\n",
    "# robust scalar is more suitable for small datasets\n",
    "# and datasets who have many abnormal data or easily \n",
    "# overfitting\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler()\n",
    "X_train_rs = rs.fit_transform(X_train)\n",
    "X_test_rs = rs.transform(X_test)\n",
    "print(pd.DataFrame(X_train_rs).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_datascience",
   "language": "python",
   "name": "env_datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
