{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "12\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "tensor([[-0.9683, -0.6123, -0.2338,  1.2812],\n",
      "        [ 0.5319, -0.9856,  1.5268, -0.6371],\n",
      "        [-0.5718, -1.5071,  0.0575, -0.3224]])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [1, 2, 3, 4],\n",
      "        [4, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# basis\n",
    "x = torch.arange(12)  # create vector/tensor, int and computed by CPU by default.\n",
    "print(x)\n",
    "print(x.shape)        # (member)access tensor's shape, length of every axis precisly.\n",
    "print(x.numel())      # (method)access tensor's size, typically (shape.x) x (shape.y)\n",
    "X = x.reshape(3, 4)   # (method)change shape of tensor by reshape. \n",
    "                      # reshape(row, column), if we use -1 in one of the parameter,\n",
    "                      # it will be autoly calculate, like: 3,-1 -> 3,4\n",
    "print(X)\n",
    "X = x.reshape(-1, 3)\n",
    "print(X)              # (member)\n",
    "print(torch.zeros((2, 3, 4)))   # (method)create a all 0s tensor, \n",
    "                                # shape(number, row, column)\n",
    "print(torch.ones((2, 3, 4)))    # (method)create a all 1s tensor, \n",
    "                                # shape(number, row, column)\n",
    "print(torch.randn(3, 4))        # (method)create a random tensor, \n",
    "                                # samples from nornal distribution\n",
    "                                # (mean value 0 and standard deviation 1)\n",
    "print(torch.tensor(data=[[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]))  # (method)create tensor by list or nested list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic operations:\n",
      "tensor([ 3.,  4.,  6., 10.])\n",
      "tensor([-1.,  0.,  2.,  6.])\n",
      "tensor([ 2.,  4.,  8., 16.])\n",
      "tensor([0.5000, 1.0000, 2.0000, 4.0000])\n",
      "tensor([ 1.,  4., 16., 64.])\n",
      "tensor([[False,  True, False,  True],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "tensor([[False, False, False, False],\n",
      "        [ True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([[ True, False,  True, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "\n",
      "torch function for maths: \n",
      "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 2,  1,  4,  3],\n",
      "        [ 1,  2,  3,  4],\n",
      "        [ 4,  3,  2,  1]])\n",
      "tensor([[ 0,  1,  2,  3,  2,  1,  4,  3],\n",
      "        [ 4,  5,  6,  7,  1,  2,  3,  4],\n",
      "        [ 8,  9, 10, 11,  4,  3,  2,  1]])\n",
      "tensor(66)\n",
      "tensor([12, 15, 18, 21])\n",
      "tensor([ 6, 22, 38])\n",
      "tensor([[ 6],\n",
      "        [22],\n",
      "        [38]])\n",
      "tensor([[ 0,  1,  3,  6],\n",
      "        [ 4,  9, 15, 22],\n",
      "        [ 8, 17, 27, 38]])\n",
      "\n",
      "production: \n",
      "tensor([12, 44, 76])\n",
      "tensor([[ 18,  15,  13],\n",
      "        [ 62,  47,  57],\n",
      "        [106,  79, 101]])\n"
     ]
    }
   ],
   "source": [
    "# operation\n",
    "\n",
    "# for same shape, operation will execute on every pair of tensor\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "X = torch.arange(12).reshape((3, 4))\n",
    "Y = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "# basic operations\n",
    "# these operations are operated on correlated elements, like (a1 */+- b1, a2 */+- b2)\n",
    "print('basic operations:')\n",
    "print(x+y)\n",
    "print(x-y)\n",
    "print(x*y)  # Hadamard production. correlated element production, not dot production.\n",
    "print(x/y)  # \n",
    "print(x**y)\n",
    "print(X==Y)\n",
    "print(X>Y)\n",
    "print(X<Y)\n",
    "\n",
    "# torch function receiving 1 or 2 parameters\n",
    "print('\\ntorch function for maths: ')\n",
    "print(torch.exp(x))\n",
    "print(torch.cat((X, Y), dim=0))  # dimension 0: vertical concatenate\n",
    "print(torch.cat((X, Y), dim=1))  # dimension 1: horizontal concatenate\n",
    "print(X.sum())\n",
    "print(X.sum(axis=0))  # aggregate rows\n",
    "print(X.sum(axis=1))  # aggregate columns\n",
    "print(X.sum(axis=1, keepdims=True))  # usually keep dimensions for columns aggregation\n",
    "print(X.cumsum(axis=1))     # aggregate rows/columns and keep result in every row/column, keep dimension\n",
    "\n",
    "# production\n",
    "print('\\nproduction: ')\n",
    "print(X.mv(y))                  # matrix-vector production\n",
    "print(X.mm(Y.reshape(4, 3)))    # matrix-matrix production, typically matrix production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "b: \n",
      " tensor([[0, 1]])\n",
      "c: \n",
      " tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]])\n",
      "a+b: \n",
      " tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]])\n",
      "b+c: \n",
      " tensor([[[0, 2],\n",
      "         [2, 4]],\n",
      "\n",
      "        [[4, 6],\n",
      "         [6, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# broadcasting\n",
    "\n",
    "# for not same shape, tensor will copy elements to \n",
    "# extend into same shape for operations\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "c = torch.arange(8).reshape((-1, 2, 2))\n",
    "print('a: \\n', a)\n",
    "print('b: \\n',b)\n",
    "print('c: \\n',c)\n",
    "print('a+b: \\n',a+b)  # a->[[0, 0], [1, 1], [2, 2]], b->[[0, 1], [0, 1], [0, 1]]\n",
    "print('b+c: \\n',b+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:\n",
      "tensor([ 8.,  9., 10., 11.])\n",
      "tensor([[ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "\n",
      "assign:\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  9.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[12., 12., 12., 12.],\n",
      "        [12., 12., 12., 12.],\n",
      "        [ 4.,  3.,  2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# index and slice\n",
    "\n",
    "# index\n",
    "print('index:')\n",
    "print(X[-1])      # access elements by actual index, -1 means the last element index\n",
    "print(X[1:3])     # access slice of tensor by :\n",
    "\n",
    "# assign\n",
    "print('\\nassign:')\n",
    "X[1, 2] = 9       # assign single element by precise index\n",
    "Y[0:2, :] = 12    # assign multiple elements by slice :\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z):  2625830886816\n",
      "id(Z):  2625830886816\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# memory cost reduction\n",
    "\n",
    "# use slice to keep operation and object local\n",
    "Z = torch.zeros_like(Y)  # use 'zeros_like' or 'ones_like' to create same shape tensor\n",
    "print('id(Z): ', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z): ', id(Z))\n",
    "\n",
    "# operate object on itself by +=, -=, *=, etc.\n",
    "id_before = id(X)\n",
    "X += Y\n",
    "id_now = id(X)\n",
    "print(id_before == id_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# transform type\n",
    "\n",
    "# numpy to torch\n",
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "print(type(A),type(B))\n",
    "\n",
    "# torch to others\n",
    "a = torch.tensor([3.5])\n",
    "print(type(a), type(a.item()))  # .item function to access scalar element"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datawhale",
   "language": "python",
   "name": "datawhale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
