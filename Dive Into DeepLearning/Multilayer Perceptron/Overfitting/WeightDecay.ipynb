{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norm in pytorch\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# create datasets\n",
    "n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5\n",
    "true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05\n",
    "\n",
    "# train data\n",
    "train_data = d2l.synthetic_data(true_w, true_b, n_train)\n",
    "train_iter = d2l.load_array(train_data, batch_size)\n",
    "\n",
    "# test data\n",
    "test_data = d2l.synthetic_data(true_w, true_b, n_test)\n",
    "test_iter = d2l.load_array(test_data, batch_size, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done\n",
      "L2 norm lambda = 0.0, accuracy of train and test:\n",
      "[tensor([2.8592e-08], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.6671e-08], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([4.7497e-09], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.6671e-08], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([4.7497e-09], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.6671e-08], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([4.7498e-09], grad_fn=<DivBackward0>), tensor([4.7498e-09], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.6671e-08], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([2.8592e-08], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([4.7498e-09], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([4.0513e-08], grad_fn=<DivBackward0>), tensor([4.7498e-09], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.4780e-07], grad_fn=<DivBackward0>), tensor([2.8592e-08], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([4.7498e-09], grad_fn=<DivBackward0>), tensor([1.6671e-08], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([7.6275e-08], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([1.6671e-08], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([7.6275e-08], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.2396e-07], grad_fn=<DivBackward0>), tensor([4.7497e-09], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.4780e-07], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([8.8196e-08], grad_fn=<DivBackward0>), tensor([1.4780e-07], grad_fn=<DivBackward0>), tensor([1.0012e-07], grad_fn=<DivBackward0>), tensor([1.3588e-07], grad_fn=<DivBackward0>), tensor([1.1204e-07], grad_fn=<DivBackward0>)]\n",
      "[tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>), tensor([-2.9235], grad_fn=<DivBackward0>)]\n",
      "train done\n",
      "L2 norm lambda = 3, accuracy of train and test:\n",
      "[tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>), tensor([-0.0337], grad_fn=<DivBackward0>)]\n",
      "[tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>), tensor([-0.3434], grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "net = nn.Sequential(nn.Linear(num_inputs, 1))\n",
    "\n",
    "# initialize parameters\n",
    "# def initialize_weights(net):\n",
    "#     if type(net) == nn.Linear:\n",
    "#         nn.init.normal_(net.weight, std=0.01)\n",
    "# net.apply(initialize_weights)\n",
    "for param in net.parameters():\n",
    "        param.data.normal_()\n",
    "\n",
    "# loss\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "# optimizer with L2 norm !!\n",
    "L2_1 = 0\n",
    "L2_2 = 3\n",
    "optimizer_1 = torch.optim.SGD([{'params':net[0].weight, 'weight_decay':L2_1}, \n",
    "                               {'params':net[0].bias}], lr=0.003)\n",
    "optimizer_2 = torch.optim.SGD([{'params':net[0].weight, 'weight_decay':L2_2}, \n",
    "                               {'params':net[0].bias}], lr=0.003)\n",
    "\n",
    "# accuracy\n",
    "def accuracy(y_hat, y):\n",
    "    difference = y_hat.type(y.dtype) - y\n",
    "    return sum(difference) / len(difference)\n",
    "\n",
    "# tain with L2 norm\n",
    "n_epochs = 100\n",
    "def train(net, minibatch_data, n_epochs, loss, optimizer):\n",
    "    net.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X, y in minibatch_data:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.mean().backward()\n",
    "            optimizer.step()\n",
    "    print(\"train done\")\n",
    "\n",
    "def evaluate(net, data, n_epochs):\n",
    "    net.eval()\n",
    "    accuracy_epoch = []\n",
    "    for n in range(n_epochs):\n",
    "        accuracy_batch = []\n",
    "        for X, y in data:\n",
    "            y_hat = net(X)\n",
    "            accuracy_batch.append(accuracy(y_hat, y))\n",
    "            a_avg = sum(accuracy_batch) / len(accuracy_batch)\n",
    "        accuracy_epoch.append(a_avg)\n",
    "    return accuracy_epoch\n",
    "            \n",
    "\n",
    "train(net, train_iter, n_epochs, loss, optimizer_1)\n",
    "net[0].weight.grad.zero_()\n",
    "net[0].bias.grad.zero_()\n",
    "\n",
    "train_accuracy = evaluate(net, train_iter, 100)\n",
    "test_accuracy = evaluate(net, test_iter, 100)\n",
    "print('L2 norm lambda = 0.0, accuracy of train and test:')\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)\n",
    "\n",
    "train(net, train_iter, n_epochs, loss, optimizer_2)\n",
    "net[0].weight.grad.zero_()\n",
    "net[0].bias.grad.zero_()\n",
    "\n",
    "train_accuracy = evaluate(net, train_iter, 100)\n",
    "test_accuracy = evaluate(net, test_iter, 100)\n",
    "print('L2 norm lambda = 3, accuracy of train and test:')\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datawhale",
   "language": "python",
   "name": "datawhale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
